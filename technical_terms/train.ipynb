{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["from datasets import load_dataset, Audio \n","\n","csv_path = '/kaggle/input/technical-terms-dataset/data_technical_terms.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(csv_path)\n","\n","df['audio_path'] = df['audio_path'].apply(lambda x: f\"/kaggle/input/technical-terms-dataset/audio_output/{x}\")\n","\n","df.to_csv('updated_file.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os.path\n","os.path.isfile('/kaggle/input/technical-terms-dataset/audio_output/audio_output/ad_10_20241019_162519.wav')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"csv\", data_files=\"./updated_file.csv\")\n","\n","dataset = dataset.cast_column(\"audio_path\", Audio(sampling_rate=16e3))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = dataset['train']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech\n","\n","\n","processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\", device='cuda')\n","model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\", device_map='cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tokenizer = processor.tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def extract_all_chars(batch):\n","    all_text = \" \".join(batch[\"sentence\"])\n","    vocab = list(set(all_text))\n","    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n","\n","vocabs = dataset.map(\n","    extract_all_chars,\n","    batched=True,\n","    batch_size=-1,\n","    keep_in_memory=True,\n","    remove_columns=dataset.column_names,\n",")\n","\n","dataset_vocab = set(vocabs[\"vocab\"][0])\n","tokenizer_vocab = {k for k,_ in tokenizer.get_vocab().items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset_vocab - tokenizer_vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import torch\n","from speechbrain.pretrained import EncoderClassifier\n","\n","spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","speaker_model = EncoderClassifier.from_hparams(\n","    source=spk_model_name,\n","    run_opts={\"device\": device},\n","    savedir=os.path.join(\"/tmp\", spk_model_name)\n",")\n","\n","def create_speaker_embedding(waveform):\n","    with torch.no_grad():\n","        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n","        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n","        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n","    return speaker_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def prepare_dataset(example):\n","    audio = example[\"audio_path\"]\n","    print(audio)\n","\n","    example = processor(\n","        text=example[\"sentence\"],\n","        audio_target=audio[\"array\"],\n","        sampling_rate=audio[\"sampling_rate\"],\n","        return_attention_mask=False,\n","    )\n","\n","    example[\"labels\"] = example[\"labels\"][0]\n","\n","    example[\"speaker_embeddings\"] = create_speaker_embedding(audio[\"array\"])\n","\n","    return example"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(dataset[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["processed_example = prepare_dataset(dataset[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["list(processed_example.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tokenizer.decode(processed_example['input_ids'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["processed_example['speaker_embeddings'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import SpeechT5HifiGan\n","\n","vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n","\n","spectrogram = torch.tensor(processed_example['labels'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    speech = vocoder(spectrogram)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from IPython.display import Audio \n","Audio(speech.cpu().numpy(), rate=16000)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = dataset.map( \n","    prepare_dataset,\n","    remove_columns=dataset.column_names,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def is_not_too_long(input_ids):\n","    input_length = len(input_ids)\n","    return input_length < 200\n","\n","dataset = dataset.filter(is_not_too_long, input_columns=[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = dataset.train_test_split(test_size=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","\n","@dataclass\n","class TTSDataCollatorWithPadding:\n","    processor: Any\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","\n","        input_ids = [{\"input_ids\": feature[\"input_ids\"]} for feature in features]\n","        label_features = [{\"input_values\": feature[\"labels\"]} for feature in features]\n","        speaker_features = [feature[\"speaker_embeddings\"] for feature in features]\n","\n","        # collate the inputs and targets into a batch\n","        batch = processor.pad(\n","            input_ids=input_ids,\n","            labels=label_features,\n","            return_tensors=\"pt\",\n","        )\n","\n","        # replace padding with -100 to ignore loss correctly\n","        batch[\"labels\"] = batch[\"labels\"].masked_fill(\n","            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100\n","        )\n","\n","        # not used during fine-tuning\n","        del batch[\"decoder_attention_mask\"]\n","\n","        # round down target lengths to multiple of reduction factor\n","        if model.config.reduction_factor > 1:\n","            target_lengths = torch.tensor([\n","                len(feature[\"input_values\"]) for feature in label_features\n","            ])\n","            target_lengths = target_lengths.new([\n","                length - length % model.config.reduction_factor for length in target_lengths\n","            ])\n","            max_length = max(target_lengths)\n","            batch[\"labels\"] = batch[\"labels\"][:, :max_length]\n","\n","        # also add in the speaker embeddings\n","        batch[\"speaker_embeddings\"] = torch.tensor(speaker_features)\n","\n","        return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_collator = TTSDataCollatorWithPadding(processor=processor)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["features = [\n","    dataset[\"train\"][0], \n","    dataset[\"train\"][1], \n","    dataset[\"train\"][20], \n","]\n","\n","batch = data_collator(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["{k:v.shape for k,v in batch.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.config.use_cache = False"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n","\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"final_technical_terms_t5_finetuned\",  \n","    per_device_train_batch_size=32,\n","    gradient_accumulation_steps=3,\n","    learning_rate=5e-4,\n","    warmup_steps=100,\n","    # max_steps=8000,\n","    num_train_epochs=50,\n","    gradient_checkpointing=True,\n","    fp16=True,\n","    evaluation_strategy=\"steps\",\n","    per_device_eval_batch_size=2,\n","    save_steps=1000,\n","    optim=\"adamw_bnb_8bit\",\n","    eval_steps=200,\n","    report_to=[\"tensorboard\"],\n","    load_best_model_at_end=True,\n","    greater_is_better=False,\n","    label_names=[\"labels\"],\n","    push_to_hub=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    args=training_args,\n","    model=model,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    tokenizer=processor.tokenizer,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.train()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5910780,"sourceId":9672217,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
