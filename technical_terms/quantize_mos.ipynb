{"cells":[{"cell_type":"code","execution_count":77,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-21T10:27:32.094189Z","iopub.status.busy":"2024-10-21T10:27:32.093140Z","iopub.status.idle":"2024-10-21T10:27:32.098455Z","shell.execute_reply":"2024-10-21T10:27:32.097638Z","shell.execute_reply.started":"2024-10-21T10:27:32.094146Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset, Audio \n","\n","csv_path = '/kaggle/input/technical-terms-dataset/data_technical_terms.csv'"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:27:32.105074Z","iopub.status.busy":"2024-10-21T10:27:32.104803Z","iopub.status.idle":"2024-10-21T10:27:32.111551Z","shell.execute_reply":"2024-10-21T10:27:32.110616Z","shell.execute_reply.started":"2024-10-21T10:27:32.105044Z"},"trusted":true},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:27:32.118163Z","iopub.status.busy":"2024-10-21T10:27:32.117878Z","iopub.status.idle":"2024-10-21T10:27:32.187638Z","shell.execute_reply":"2024-10-21T10:27:32.186693Z","shell.execute_reply.started":"2024-10-21T10:27:32.118133Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(csv_path)\n","\n","# Update the column by adding a string to each value\n","df['audio_path'] = df['audio_path'].apply(lambda x: f\"/kaggle/input/technical-terms-dataset/audio_output/{x}\")\n","\n","# Save the modified DataFrame back to a CSV file\n","df.to_csv('updated_file.csv', index=False)"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:27:32.189915Z","iopub.status.busy":"2024-10-21T10:27:32.189432Z","iopub.status.idle":"2024-10-21T10:27:32.198167Z","shell.execute_reply":"2024-10-21T10:27:32.197269Z","shell.execute_reply.started":"2024-10-21T10:27:32.189869Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["import os.path\n","os.path.isfile('/kaggle/input/technical-terms-dataset/audio_output/audio_output/ad_10_20241019_162519.wav')"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:27:32.199392Z","iopub.status.busy":"2024-10-21T10:27:32.199121Z","iopub.status.idle":"2024-10-21T10:27:32.477962Z","shell.execute_reply":"2024-10-21T10:27:32.477035Z","shell.execute_reply.started":"2024-10-21T10:27:32.199361Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9e829b80c6b4e108bde9e079b930fc9","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset(\"csv\", data_files=\"./updated_file.csv\")\n","\n","dataset = dataset.cast_column(\"audio_path\", Audio(sampling_rate=16e3))"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:27:32.480440Z","iopub.status.busy":"2024-10-21T10:27:32.480132Z","iopub.status.idle":"2024-10-21T10:27:32.484990Z","shell.execute_reply":"2024-10-21T10:27:32.484044Z","shell.execute_reply.started":"2024-10-21T10:27:32.480407Z"},"trusted":true},"outputs":[],"source":["dataset = dataset['train']"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:27:32.486540Z","iopub.status.busy":"2024-10-21T10:27:32.486232Z","iopub.status.idle":"2024-10-21T10:27:32.497798Z","shell.execute_reply":"2024-10-21T10:27:32.496940Z","shell.execute_reply.started":"2024-10-21T10:27:32.486507Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.select(range(30))"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:27:32.499651Z","iopub.status.busy":"2024-10-21T10:27:32.499287Z","iopub.status.idle":"2024-10-21T10:27:32.504868Z","shell.execute_reply":"2024-10-21T10:27:32.503992Z","shell.execute_reply.started":"2024-10-21T10:27:32.499594Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n","from datasets import load_dataset\n","import soundfile as sf\n","from pesq import pesq\n","from scipy.io import wavfile\n","import numpy as np\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing sample 0\n","Processing sample 1\n","Processing sample 2\n","Processing sample 3\n","Processing sample 4\n","Processing sample 5\n","Processing sample 6\n","Processing sample 7\n","Processing sample 8\n","Processing sample 9\n","Processing sample 10\n","Processing sample 11\n","Processing sample 12\n","Processing sample 13\n","Processing sample 14\n","Processing sample 15\n","Processing sample 16\n","Processing sample 17\n","Processing sample 18\n","Processing sample 19\n","Processing sample 20\n","Processing sample 21\n","Processing sample 22\n","Processing sample 23\n","Processing sample 24\n","Processing sample 25\n","Processing sample 26\n","Processing sample 27\n","Processing sample 28\n","Processing sample 29\n","Average Log Spectral Distance (LSD) score: 2.0446481704711914\n","Average MOS score (from LSD): 4.1821407731374105\n"]}],"source":["import numpy as np\n","import librosa\n","import torch\n","from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n","import soundfile as sf\n","from scipy.io import wavfile\n","\n","lsd_scores = []\n","mos_scores = []\n","\n","LSD_MIN = 0 \n","LSD_MAX = 10  \n","\n","def log_spectral_distance(ref_audio, gen_audio, sr=16000):\n","    min_length = min(len(ref_audio), len(gen_audio))\n","    ref_audio = ref_audio[:min_length]\n","    gen_audio = gen_audio[:min_length]\n","\n","    ref_spectrum = np.abs(librosa.stft(ref_audio))\n","    gen_spectrum = np.abs(librosa.stft(gen_audio))\n","    ref_log = np.log(ref_spectrum + 1e-10)  \n","    gen_log = np.log(gen_spectrum + 1e-10)\n","    lsd = np.mean(np.sqrt(np.mean((ref_log - gen_log) ** 2, axis=0)))\n","    return lsd\n","\n","def normalize_lsd_to_mos(lsd_score, lsd_min, lsd_max):\n","    if lsd_score < lsd_min:\n","        return 5.0 \n","    elif lsd_score > lsd_max:\n","        return 1.0  \n","    else:\n","        return 5 - ((lsd_score - lsd_min) / (lsd_max - lsd_min) * 4)\n","\n","x = 0\n","for sample in dataset:\n","    text = sample['sentence'] \n","    original_audio_path = sample['audio_path']['path']  \n","\n"," \n","    inputs = processor(text=text, return_tensors=\"pt\")\n","    generated_speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n","\n","    generated_audio_path = \"generated_speech.wav\"\n","    sf.write(generated_audio_path, generated_speech.numpy(), samplerate=16000)\n","    print(f\"Processing sample {x}\")\n","    x += 1\n","\n","    fs_ref, ref_audio = wavfile.read(original_audio_path)\n","    fs_deg, deg_audio = wavfile.read(generated_audio_path)\n","\n","    if ref_audio.dtype == np.int16:\n","        ref_audio = ref_audio.astype(np.float32) / np.iinfo(np.int16).max  \n","    if deg_audio.dtype == np.int16:\n","        deg_audio = deg_audio.astype(np.float32) / np.iinfo(np.int16).max \n","\n","    if fs_ref == fs_deg == 16000:\n","        try:\n","            lsd_score = log_spectral_distance(ref_audio, deg_audio, sr=16000)\n","            lsd_scores.append(lsd_score)\n","#             print(f\"LSD score: {lsd_score}\")\n","\n","            mos_score = normalize_lsd_to_mos(lsd_score, LSD_MIN, LSD_MAX)\n","            mos_scores.append(mos_score)\n","#             print(f\"MOS score (from LSD): {mos_score}\")\n","\n","        except Exception as e:\n","            print(f\"Error computing LSD for sample {sample['audio_path']['path']}: {e}\")\n","    else:\n","        print(f\"Sample rate mismatch for {sample['audio_path']['path']}\")\n","\n","average_lsd = np.mean(lsd_scores)\n","average_mos = np.mean(mos_scores)\n","\n","print(f\"Average Log Spectral Distance (LSD) score: {average_lsd}\")\n","print(f\"Average MOS score (from LSD): {average_mos}\")\n"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:27:34.594452Z","iopub.status.busy":"2024-10-21T10:27:34.594140Z","iopub.status.idle":"2024-10-21T10:27:42.143386Z","shell.execute_reply":"2024-10-21T10:27:42.142463Z","shell.execute_reply.started":"2024-10-21T10:27:34.594419Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Applying light pruning...\n","Applying minimal quantization...\n"]}],"source":["from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n","from datasets import load_dataset\n","import torch\n","import torch.nn.utils.prune as prune\n","import soundfile as sf\n","from datasets import load_dataset\n","\n","def prune_model(model, amount=0.15):\n","    \"\"\"\n","    Apply L1 unstructured pruning only to specific layers\n","    amount: percentage of weights to prune (0.15 = 15%)\n","    \"\"\"\n","    for name, module in model.named_modules():\n","        # Only prune specific layers to maintain quality\n","        if isinstance(module, torch.nn.Linear) and ('encoder.feed_forward' in name):\n","            prune.l1_unstructured(module, name='weight', amount=amount)\n","            prune.remove(module, 'weight')\n","\n","def apply_selective_quantization(model):\n","    \"\"\"\n","    Apply very light quantization only to specific layers\n","    that don't heavily impact audio quality\n","    \"\"\"\n","    quantized_model = torch.quantization.quantize_dynamic(\n","        model,\n","        {torch.nn.Linear}, \n","        dtype=torch.float16,  \n","        inplace=True\n","    )\n","    \n","    return quantized_model\n","\n","# model = SpeechT5ForTextToSpeech.from_pretrained(\"aarishshahmohsin/final_technical_terms_t5_finetuned\")\n","\n","print(\"Applying light pruning...\")\n","prune_model(model)\n","\n","print(\"Applying minimal quantization...\")\n","model = apply_selective_quantization(model)"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:30:39.647589Z","iopub.status.busy":"2024-10-21T10:30:39.646784Z","iopub.status.idle":"2024-10-21T10:32:25.791742Z","shell.execute_reply":"2024-10-21T10:32:25.790700Z","shell.execute_reply.started":"2024-10-21T10:30:39.647551Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing sample 0\n","Processing sample 1\n","Processing sample 2\n","Processing sample 3\n","Processing sample 4\n","Processing sample 5\n","Processing sample 6\n","Processing sample 7\n","Processing sample 8\n","Processing sample 9\n","Processing sample 10\n","Processing sample 11\n","Processing sample 12\n","Processing sample 13\n","Processing sample 14\n","Processing sample 15\n","Processing sample 16\n","Processing sample 17\n","Processing sample 18\n","Processing sample 19\n","Processing sample 20\n","Processing sample 21\n","Processing sample 22\n","Processing sample 23\n","Processing sample 24\n","Processing sample 25\n","Processing sample 26\n","Processing sample 27\n","Processing sample 28\n","Processing sample 29\n","Average Log Spectral Distance (LSD) score: 2.0446481704711914\n","Average MOS score (from LSD): 4.1821407731374105\n"]}],"source":["import numpy as np\n","import librosa\n","import torch\n","from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n","import soundfile as sf\n","from scipy.io import wavfile\n","\n","lsd_scores = []\n","mos_scores = []\n","\n","LSD_MIN = 0 \n","LSD_MAX = 10  \n","\n","def log_spectral_distance(ref_audio, gen_audio, sr=16000):\n","    min_length = min(len(ref_audio), len(gen_audio))\n","    ref_audio = ref_audio[:min_length]\n","    gen_audio = gen_audio[:min_length]\n","\n","    ref_spectrum = np.abs(librosa.stft(ref_audio))\n","    gen_spectrum = np.abs(librosa.stft(gen_audio))\n","    ref_log = np.log(ref_spectrum + 1e-10)  \n","    gen_log = np.log(gen_spectrum + 1e-10)\n","    lsd = np.mean(np.sqrt(np.mean((ref_log - gen_log) ** 2, axis=0)))\n","    return lsd\n","\n","def normalize_lsd_to_mos(lsd_score, lsd_min, lsd_max):\n","    if lsd_score < lsd_min:\n","        return 5.0 \n","    elif lsd_score > lsd_max:\n","        return 1.0  \n","    else:\n","        return 5 - ((lsd_score - lsd_min) / (lsd_max - lsd_min) * 4)\n","\n","x = 0\n","for sample in dataset:\n","    text = sample['sentence'] \n","    original_audio_path = sample['audio_path']['path']  \n","\n"," \n","    inputs = processor(text=text, return_tensors=\"pt\")\n","    generated_speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n","\n","    generated_audio_path = \"generated_speech.wav\"\n","    sf.write(generated_audio_path, generated_speech.numpy(), samplerate=16000)\n","    print(f\"Processing sample {x}\")\n","    x += 1\n","\n","    fs_ref, ref_audio = wavfile.read(original_audio_path)\n","    fs_deg, deg_audio = wavfile.read(generated_audio_path)\n","\n","    if ref_audio.dtype == np.int16:\n","        ref_audio = ref_audio.astype(np.float32) / np.iinfo(np.int16).max  \n","    if deg_audio.dtype == np.int16:\n","        deg_audio = deg_audio.astype(np.float32) / np.iinfo(np.int16).max \n","\n","    if fs_ref == fs_deg == 16000:\n","        try:\n","            lsd_score = log_spectral_distance(ref_audio, deg_audio, sr=16000)\n","            lsd_scores.append(lsd_score)\n","#             print(f\"LSD score: {lsd_score}\")\n","\n","            mos_score = normalize_lsd_to_mos(lsd_score, LSD_MIN, LSD_MAX)\n","            mos_scores.append(mos_score)\n","#             print(f\"MOS score (from LSD): {mos_score}\")\n","\n","        except Exception as e:\n","            print(f\"Error computing LSD for sample {sample['audio_path']['path']}: {e}\")\n","    else:\n","        print(f\"Sample rate mismatch for {sample['audio_path']['path']}\")\n","\n","average_lsd = np.mean(lsd_scores)\n","average_mos = np.mean(mos_scores)\n","\n","print(f\"Average Log Spectral Distance (LSD) score: {average_lsd}\")\n","print(f\"Average MOS score (from LSD): {average_mos}\")\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5910780,"sourceId":9672217,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
