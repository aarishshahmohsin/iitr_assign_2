{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","\n","ds = load_dataset(\"UmarRamzan/common-voice-urdu-processed\")\n","train_data = ds['train']\n","test_data = ds['test']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data = train_data.remove_columns([\"path\", \"variant\"])\n","train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import Audio\n","train_data\n","train_data = train_data.cast_column(\"audio\", Audio(sampling_rate=16000))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import SpeechT5Processor\n","\n","checkpoint = \"microsoft/speecht5_tts\"\n","processor = SpeechT5Processor.from_pretrained(checkpoint)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tokenizer = processor.tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data[2: 5]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data[0: 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_urdu_tokens():\n","    tokens = [char for char in \"ابپتٹثجچحخدڈذرڑزژسشصضطظعغفقکلمنوہھیےأؤئگںۂۃۓ\"]\n","    return tokens\n","\n","\n","tokenizer.add_tokens(get_urdu_tokens())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def extract_all_chars(batch):\n","    all_text = \" \".join(batch[\"sentence\"])\n","    vocab = list(set(all_text))\n","    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n","\n","\n","vocabs = train_data.map(\n","    extract_all_chars,\n","    batched=True,\n","    batch_size=-1,\n","    keep_in_memory=True,\n","    remove_columns=train_data.column_names,\n",")\n","\n","dataset_vocab = set(vocabs[\"vocab\"][0])\n","tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(tokenizer_vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import re \n","\n","def normalize(text):\n","\n","    text = re.sub(r'[^\\w\\s\\']', '', text)\n","\n","    # Remove extra whitespace\n","    text = ' '.join(text.split())\n","\n","    urdu = {\n","        'ا':['إ','أ','ئ','ؤ'],\n","        'ق':['غ'], 'ز':['ظ','ض','ذ'],\n","        'س':['ص','ث'], 'ت':['ط','ة'],\n","        'ک':['ك'], '':['ّ', 'ً'], ',':'،'}\n","\n","    for key in urdu:\n","        for char in urdu[key]:\n","            text = text.replace(char, key)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def add_normalized_text(example):\n","    example['normalized_text'] = normalize(example['sentence'])\n","    return example\n","\n","\n","train_data = train_data.map(add_normalized_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i in train_data[0: 1]:\n","    print(len(train_data[0: 1][i][0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def extract_all_chars(batch):\n","    all_text = \" \".join(batch[\"normalized_text\"])\n","    vocab = list(set(all_text))\n","    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n","\n","\n","vocabs = train_data.map(\n","    extract_all_chars,\n","    batched=True,\n","    batch_size=-1,\n","    keep_in_memory=True,\n","    remove_columns=train_data.column_names,\n",")\n","\n","dataset_vocab = set(vocabs[\"vocab\"][0])\n","tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset_vocab - tokenizer_vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for feature in train_data.features:\n","    print(feature)\n","    print(train_data[0][feature])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import torch\n","from speechbrain.pretrained import EncoderClassifier\n","\n","spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# device='cpu'\n","speaker_model = EncoderClassifier.from_hparams(\n","    source=spk_model_name,\n","    run_opts={\"device\": device},\n","    savedir=os.path.join(\"/tmp\", spk_model_name),\n",")\n","\n","\n","def create_speaker_embedding(waveform):\n","    with torch.no_grad():\n","        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n","        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n","        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n","    return speaker_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def prepare_dataset(example):\n","    audio = example[\"audio\"]\n","\n","    example = processor(\n","        text=example[\"normalized_text\"],\n","        audio_target=audio[\"array\"],\n","        sampling_rate=audio[\"sampling_rate\"],\n","        return_attention_mask=False,\n","    )\n","\n","    # strip off the batch dimension\n","    example[\"labels\"] = example[\"labels\"][0]\n","\n","    # use SpeechBrain to obtain x-vector\n","    example[\"speaker_embeddings\"] = create_speaker_embedding(audio[\"array\"])\n","\n","    return example"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["processed_example = prepare_dataset(train_data[8])\n","list(processed_example.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["processed_example[\"speaker_embeddings\"].shape\n","len(processed_example[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data = train_data.map(prepare_dataset, remove_columns=train_data.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def is_not_too_long(input_ids):\n","    input_length = len(input_ids)\n","    return input_length < 200\n","\n","train_data = train_data.filter(is_not_too_long, input_columns=[\"input_ids\"])\n","len(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data = train_data.train_test_split(test_size=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","\n","\n","@dataclass\n","class TTSDataCollatorWithPadding:\n","    processor: Any\n","\n","    def __call__(\n","        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n","    ) -> Dict[str, torch.Tensor]:\n","        input_ids = [{\"input_ids\": feature[\"input_ids\"]} for feature in features]\n","        label_features = [{\"input_values\": feature[\"labels\"]} for feature in features]\n","        speaker_features = [feature[\"speaker_embeddings\"] for feature in features]\n","\n","        # collate the inputs and targets into a batch\n","        batch = processor.pad(\n","            input_ids=input_ids, labels=label_features, return_tensors=\"pt\"\n","        )\n","\n","        # replace padding with -100 to ignore loss correctly\n","        batch[\"labels\"] = batch[\"labels\"].masked_fill(\n","            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100\n","        )\n","\n","        # not used during fine-tuning\n","        del batch[\"decoder_attention_mask\"]\n","\n","        # round down target lengths to multiple of reduction factor\n","        if model.config.reduction_factor > 1:\n","            target_lengths = torch.tensor(\n","                [len(feature[\"input_values\"]) for feature in label_features]\n","            )\n","            target_lengths = target_lengths.new(\n","                [\n","                    length - length % model.config.reduction_factor\n","                    for length in target_lengths\n","                ]\n","            )\n","            max_length = max(target_lengths)\n","            batch[\"labels\"] = batch[\"labels\"][:, :max_length]\n","\n","        # also add in the speaker embeddings\n","        batch[\"speaker_embeddings\"] = torch.tensor(speaker_features)\n","\n","        return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_collator = TTSDataCollatorWithPadding(processor=processor)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import SpeechT5ForTextToSpeech\n","\n","model = SpeechT5ForTextToSpeech.from_pretrained(checkpoint)\n","model = model.to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from functools import partial\n","\n","# disable cache during training since it's incompatible with gradient checkpointing\n","model.config.use_cache = False\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# set language and task for generation and re-enable cache\n","model.generate = partial(model.generate, use_cache=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n","\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"final_urdu_t5_finetuned\", \n","    per_device_train_batch_size=64,\n","    gradient_accumulation_steps=4,\n","    learning_rate=2e-4,\n","    warmup_steps=100,\n","    max_steps=10000,\n","    gradient_checkpointing=True,\n","    fp16=True,\n","    evaluation_strategy=\"steps\",\n","    per_device_eval_batch_size=2,\n","    save_steps=10000,\n","    eval_steps=500,\n","    logging_steps=25,\n","    optim=\"adamw_bnb_8bit\",\n","    report_to=[\"tensorboard\"],\n","    load_best_model_at_end=True,\n","    greater_is_better=False,\n","    label_names=[\"labels\"],\n","    push_to_hub=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer = Seq2SeqTrainer(\n","    args=training_args,\n","    model=model,\n","    train_dataset=train_data['train'],\n","    eval_dataset=train_data['test'],\n","    data_collator=data_collator,\n","    tokenizer=processor,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.push_to_hub()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
