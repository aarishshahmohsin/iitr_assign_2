{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9672217,"sourceType":"datasetVersion","datasetId":5910780}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset, concatenate_datasets\n\nds = load_dataset(\"UmarRamzan/common-voice-urdu-processed\")\ntrain_data = ds['train']\ntest_data = ds['test']\ndataset = concatenate_datasets([train_data, test_data])\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-21T10:52:33.107290Z","iopub.execute_input":"2024-10-21T10:52:33.108055Z","iopub.status.idle":"2024-10-21T10:52:34.561407Z","shell.execute_reply.started":"2024-10-21T10:52:33.108012Z","shell.execute_reply":"2024-10-21T10:52:34.560617Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-10-21T10:52:34.563056Z","iopub.execute_input":"2024-10-21T10:52:34.563366Z","iopub.status.idle":"2024-10-21T10:52:34.567510Z","shell.execute_reply.started":"2024-10-21T10:52:34.563332Z","shell.execute_reply":"2024-10-21T10:52:34.566571Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.select(range(10))","metadata":{"execution":{"iopub.status.busy":"2024-10-21T10:52:34.568658Z","iopub.execute_input":"2024-10-21T10:52:34.569066Z","iopub.status.idle":"2024-10-21T10:52:34.579280Z","shell.execute_reply.started":"2024-10-21T10:52:34.569032Z","shell.execute_reply":"2024-10-21T10:52:34.578342Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\nfrom datasets import load_dataset\nimport soundfile as sf\nfrom pesq import pesq\nfrom scipy.io import wavfile\nimport numpy as np\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T10:52:34.581536Z","iopub.execute_input":"2024-10-21T10:52:34.581854Z","iopub.status.idle":"2024-10-21T10:52:34.587431Z","shell.execute_reply.started":"2024-10-21T10:52:34.581821Z","shell.execute_reply":"2024-10-21T10:52:34.586525Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"processor = SpeechT5Processor.from_pretrained(\"aarishshahmohsin/urdu_processor_t5\")\nmodel = SpeechT5ForTextToSpeech.from_pretrained(\"aarishshahmohsin/final_urdu_t5_finetuned\")\nvocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n\n\nembeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\nspeaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0) ","metadata":{"execution":{"iopub.status.busy":"2024-10-21T10:52:34.588692Z","iopub.execute_input":"2024-10-21T10:52:34.589138Z","iopub.status.idle":"2024-10-21T10:52:36.705134Z","shell.execute_reply.started":"2024-10-21T10:52:34.589092Z","shell.execute_reply":"2024-10-21T10:52:36.703605Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport librosa\nimport torch\nfrom transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\nimport soundfile as sf\nfrom scipy.io import wavfile\n\n# Initialize scores lists\nlsd_scores = []\nmos_scores = []\n\n# Define LSD thresholds for normalization to MOS\nLSD_MIN = 5 \nLSD_MAX = 20  \n\n# Function to compute Log Spectral Distance (LSD)\ndef log_spectral_distance(ref_audio, gen_audio, sr=16000):\n    min_length = min(len(ref_audio), len(gen_audio))\n    ref_audio = ref_audio[:min_length]\n    gen_audio = gen_audio[:min_length]\n\n    ref_spectrum = np.abs(librosa.stft(ref_audio))\n    gen_spectrum = np.abs(librosa.stft(gen_audio))\n    ref_log = np.log(ref_spectrum + 1e-10)  \n    gen_log = np.log(gen_spectrum + 1e-10)\n    lsd = np.mean(np.sqrt(np.mean((ref_log - gen_log) ** 2, axis=0)))\n    return lsd\n\n# Function to normalize LSD scores to MOS scale\ndef normalize_lsd_to_mos(lsd_score, lsd_min, lsd_max):\n    if lsd_score < lsd_min:\n        return 5.0  # Best quality\n    elif lsd_score > lsd_max:\n        return 1.0  # Worst quality\n    else:\n        return 5 - ((lsd_score - lsd_min) / (lsd_max - lsd_min) * 4)\n\n\n# Sample processing loop\nx = 0\nfor sample in dataset:\n    text = sample['sentence']  # Assuming this is the text to synthesize\n    original_audio_array = sample['audio']['array']  # Use the audio array from the dataset\n\n    # Generate speech from text\n    inputs = processor(text=text, return_tensors=\"pt\")\n    generated_speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n\n    # Save the generated speech to a WAV file\n    generated_audio_path = \"generated_speech.wav\"\n    sf.write(generated_audio_path, generated_speech.numpy(), samplerate=16000)\n    print(f\"Processing sample {x}\")\n    x += 1\n\n    # Convert the original audio array to float format if necessary\n    if original_audio_array.dtype == np.int16:\n        original_audio_array = original_audio_array.astype(np.float32) / np.iinfo(np.int16).max  # Scale to [-1.0, 1.0]\n\n    # Save the original audio array to a WAV file\n    original_audio_path = f\"original_audio_{x}.wav\"\n    sf.write(original_audio_path, original_audio_array, samplerate=16000)\n\n    # Compute the Log Spectral Distance (LSD)\n    fs_ref, ref_audio = wavfile.read(original_audio_path)\n    fs_deg, deg_audio = wavfile.read(generated_audio_path)\n\n    # Ensure both audios have the same sample rate\n    if fs_ref == fs_deg == 16000:\n        \n        lsd_score = log_spectral_distance(original_audio_array, generated_speech.numpy(), sr=16000)\n        lsd_scores.append(lsd_score)\n        print(lsd_score)\n\n        # Normalize LSD score to MOS range\n        mos_score = normalize_lsd_to_mos(lsd_score, LSD_MIN, LSD_MAX)\n        mos_scores.append(mos_score)\n        print(mos_score)\n    else:\n        print(f\"Sample rate mismatch\")\n\n# Calculate the average scores\naverage_lsd = np.mean(lsd_scores)\naverage_mos = np.mean(mos_scores)\n\nprint(f\"Average Log Spectral Distance (LSD) score: {average_lsd}\")\nprint(f\"Average MOS score (from LSD): {average_mos}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T10:52:36.706974Z","iopub.execute_input":"2024-10-21T10:52:36.707425Z","iopub.status.idle":"2024-10-21T10:53:05.438329Z","shell.execute_reply.started":"2024-10-21T10:52:36.707370Z","shell.execute_reply":"2024-10-21T10:53:05.437257Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"Processing sample 0\n8.592618581798998\n4.041968378186934\nProcessing sample 1\n9.35345217453587\n3.839079420123768\nProcessing sample 2\n10.543334831137045\n3.5217773783634545\nProcessing sample 3\n11.684107309375568\n3.217571384166515\nProcessing sample 4\n10.71150095313978\n3.4769330791627255\nProcessing sample 5\n10.930715643798537\n3.41847582832039\nProcessing sample 6\n8.296943636303336\n4.12081503031911\nProcessing sample 7\n8.692879204145214\n4.015232212227943\nProcessing sample 8\n8.779797434336793\n3.9920540175101884\nProcessing sample 9\n9.233099076095282\n3.871173579707925\nAverage Log Spectral Distance (LSD) score: 9.681844884466644\nAverage MOS score (from LSD): 3.7515080308088953\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\nfrom datasets import load_dataset\nimport torch\nimport torch.nn.utils.prune as prune\nimport soundfile as sf\nfrom datasets import load_dataset\n\ndef prune_model(model, amount=0.15):\n    \"\"\"\n    Apply L1 unstructured pruning only to specific layers\n    amount: percentage of weights to prune (0.15 = 15%)\n    \"\"\"\n    for name, module in model.named_modules():\n        # Only prune specific layers to maintain quality\n        if isinstance(module, torch.nn.Linear) and ('encoder.feed_forward' in name):\n            prune.l1_unstructured(module, name='weight', amount=amount)\n            prune.remove(module, 'weight')\n\ndef apply_selective_quantization(model):\n    \"\"\"\n    Apply very light quantization only to specific layers\n    that don't heavily impact audio quality\n    \"\"\"\n    quantized_model = torch.quantization.quantize_dynamic(\n        model,\n        {torch.nn.Linear}, \n        dtype=torch.float16,  \n        inplace=True\n    )\n    \n    return quantized_model\n\n# model = SpeechT5ForTextToSpeech.from_pretrained(\"aarishshahmohsin/final_technical_terms_t5_finetuned\")\n\nprint(\"Applying light pruning...\")\nprune_model(model)\n\nprint(\"Applying minimal quantization...\")\nmodel = apply_selective_quantization(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T10:53:05.439599Z","iopub.execute_input":"2024-10-21T10:53:05.439969Z","iopub.status.idle":"2024-10-21T10:53:13.020533Z","shell.execute_reply.started":"2024-10-21T10:53:05.439933Z","shell.execute_reply":"2024-10-21T10:53:13.019509Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"Applying light pruning...\nApplying minimal quantization...\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-21T10:53:13.021877Z","iopub.execute_input":"2024-10-21T10:53:13.022199Z","iopub.status.idle":"2024-10-21T10:53:13.035940Z","shell.execute_reply.started":"2024-10-21T10:53:13.022166Z","shell.execute_reply":"2024-10-21T10:53:13.035050Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"{'path': '/root/.cache/huggingface/datasets/downloads/extracted/98bf2841c44feb87b01d6be50c6f7419f1ac73fbf85cbe37236d236156bc5b3f/ur_train_0/common_voice_ur_31857979.mp3',\n 'audio': {'path': 'common_voice_ur_31857979.mp3',\n  'array': array([ 1.13686838e-13, -9.66338121e-13, -2.33058017e-12, ...,\n         -4.77751655e-07, -4.93692141e-07, -3.46486331e-07]),\n  'sampling_rate': 48000},\n 'sentence': 'معاشی مواقع پیدا ہوں',\n 'variant': ''}"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport librosa\nimport torch\nfrom transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\nimport soundfile as sf\nfrom scipy.io import wavfile\n\n# Initialize scores lists\nlsd_scores = []\nmos_scores = []\n\n# Define LSD thresholds for normalization to MOS\nLSD_MIN = 5 \nLSD_MAX = 20  \n\n# Function to compute Log Spectral Distance (LSD)\ndef log_spectral_distance(ref_audio, gen_audio, sr=16000):\n    min_length = min(len(ref_audio), len(gen_audio))\n    ref_audio = ref_audio[:min_length]\n    gen_audio = gen_audio[:min_length]\n\n    ref_spectrum = np.abs(librosa.stft(ref_audio))\n    gen_spectrum = np.abs(librosa.stft(gen_audio))\n    ref_log = np.log(ref_spectrum + 1e-10)  \n    gen_log = np.log(gen_spectrum + 1e-10)\n    lsd = np.mean(np.sqrt(np.mean((ref_log - gen_log) ** 2, axis=0)))\n    return lsd\n\n# Function to normalize LSD scores to MOS scale\ndef normalize_lsd_to_mos(lsd_score, lsd_min, lsd_max):\n    if lsd_score < lsd_min:\n        return 5.0  # Best quality\n    elif lsd_score > lsd_max:\n        return 1.0  # Worst quality\n    else:\n        return 5 - ((lsd_score - lsd_min) / (lsd_max - lsd_min) * 4)\n\n\n# Sample processing loop\nx = 0\nfor sample in dataset:\n    text = sample['sentence']  # Assuming this is the text to synthesize\n    original_audio_array = sample['audio']['array']  # Use the audio array from the dataset\n\n    # Generate speech from text\n    inputs = processor(text=text, return_tensors=\"pt\")\n    generated_speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n\n    # Save the generated speech to a WAV file\n    generated_audio_path = \"generated_speech.wav\"\n    sf.write(generated_audio_path, generated_speech.numpy(), samplerate=16000)\n    print(f\"Processing sample {x}\")\n    x += 1\n\n    # Convert the original audio array to float format if necessary\n    if original_audio_array.dtype == np.int16:\n        original_audio_array = original_audio_array.astype(np.float32) / np.iinfo(np.int16).max  # Scale to [-1.0, 1.0]\n\n    # Save the original audio array to a WAV file\n    original_audio_path = f\"original_audio_{x}.wav\"\n    sf.write(original_audio_path, original_audio_array, samplerate=16000)\n\n    # Compute the Log Spectral Distance (LSD)\n    fs_ref, ref_audio = wavfile.read(original_audio_path)\n    fs_deg, deg_audio = wavfile.read(generated_audio_path)\n\n    # Ensure both audios have the same sample rate\n    if fs_ref == fs_deg == 16000:\n        \n        lsd_score = log_spectral_distance(original_audio_array, generated_speech.numpy(), sr=16000)\n        lsd_scores.append(lsd_score)\n        print(lsd_score)\n\n        # Normalize LSD score to MOS range\n        mos_score = normalize_lsd_to_mos(lsd_score, LSD_MIN, LSD_MAX)\n        mos_scores.append(mos_score)\n        print(mos_score)\n    else:\n        print(f\"Sample rate mismatch\")\n\n# Calculate the average scores\naverage_lsd = np.mean(lsd_scores)\naverage_mos = np.mean(mos_scores)\n\nprint(f\"Average Log Spectral Distance (LSD) score: {average_lsd}\")\nprint(f\"Average MOS score (from LSD): {average_mos}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T10:53:13.037174Z","iopub.execute_input":"2024-10-21T10:53:13.037497Z","iopub.status.idle":"2024-10-21T10:53:41.567006Z","shell.execute_reply.started":"2024-10-21T10:53:13.037457Z","shell.execute_reply":"2024-10-21T10:53:41.566021Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"Processing sample 0\n8.914122600703172\n3.956233973145821\nProcessing sample 1\n9.086281062756157\n3.9103250499316915\nProcessing sample 2\n10.75851421884005\n3.46439620830932\nProcessing sample 3\n11.22987997338771\n3.338698673763277\nProcessing sample 4\n10.470390275456088\n3.5412292598783766\nProcessing sample 5\n10.979913771023833\n3.405356327726978\nProcessing sample 6\n8.218208450309385\n4.141811079917497\nProcessing sample 7\n8.470232891559833\n4.074604562250711\nProcessing sample 8\n9.085405482121146\n3.9105585381010277\nProcessing sample 9\n9.197052637406227\n3.8807859633583393\nAverage Log Spectral Distance (LSD) score: 9.641000136356359\nAverage MOS score (from LSD): 3.762399963638304\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}